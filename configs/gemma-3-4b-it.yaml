# Model configuration
draft_model: "google/gemma-3-270m-it"
target_model: "google/gemma-3-4b-it"

# Decoding parameters
k: 2
max_new_tokens: 256
max_length: 512

# Dataset configuration
num_samples: 20
dataset:
  path: "openai/gsm8k"
  name: "main"

# Performance settings
batch_size: 4
device: "cuda:1"
quantized: true
summary_file_name: "gemma-3-d270m-t4b-it"
