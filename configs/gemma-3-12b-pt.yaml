# Model Configs
draft:
  quantized: false
  params:
    pretrained_model_name_or_path: "google/gemma-3-1b-pt"
    device_map: "cuda:0"
    torch_dtype: "auto"
    max_memory:
      0:"5GiB"
      1:"7GiB"
target: 
  quantized: false
  params:
    pretrained_model_name_or_path: "google/gemma-3-12b-pt"
    device_map: "cpu"
    torch_dtype: "auto"
    max_memory:
      0:"5GiB"
      1:"7GiB"
    
# Generation Configs
prompt: "Once upon a time"
max_tokens: 32
k: 4
