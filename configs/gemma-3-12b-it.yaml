# Model Configs
draft:
  quantized: false
  params:
    pretrained_model_name_or_path: "models/google__gemma-3-1b-it"
    device_map: "cuda:0"
    torch_dtype: "auto"

target: 
  quantized: false
  params:
    pretrained_model_name_or_path: "models/google__gemma-3-12b-it"
    device_map: "cpu"
    torch_dtype: "auto"
    
# Generation Configs
model_collection: "gemma-3"
prompt: "Tell me a story"
max_length: 128
max_new_tokens: 32
k: 2
summary_file_name: "gemma-3-d1b-t12b-it" 
